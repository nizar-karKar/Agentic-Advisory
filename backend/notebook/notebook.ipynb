{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369aa9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing: true\n",
      "Project: langgraph_tuto_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# LangSmith\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\", \"langgraph-youtube-demo\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "print(\"Tracing:\", os.environ[\"LANGCHAIN_TRACING_V2\"])\n",
    "print(\"Project:\", os.environ[\"LANGCHAIN_PROJECT\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1a208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc_admin_0017\\Desktop\\AI-Medium-Pubisher\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any, Optional, TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4202190",
   "metadata": {},
   "source": [
    "## Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e36fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_AGENT_SYSTEM = \"\"\"You are a helpful AI.\n",
    "Task: Provide a well-reasoned recommendation to the user question.\n",
    "Rules:\n",
    "- Make your best effort without browsing the web.\n",
    "- Be structured: Summary, Pros, Cons, Recommendation, Risks, Confidence (0-100).\n",
    "\"\"\"\n",
    "\n",
    "def single_agent_answer(question: str) -> str:\n",
    "    msgs = [\n",
    "        SystemMessage(content=SINGLE_AGENT_SYSTEM),\n",
    "        HumanMessage(content=question),\n",
    "    ]\n",
    "    return llm.invoke(msgs).content\n",
    "\n",
    "question = \"Should a startup use open-source LLMs or closed models in 2026? Consider cost, speed, privacy, and reliability.\"\n",
    "print(single_agent_answer(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e42aa",
   "metadata": {},
   "source": [
    "## Multi-Agent System with LangGraph + LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d10e2",
   "metadata": {},
   "source": [
    "\n",
    "*   Planner: Breaks the userâ€™s question into a clear plan, key risks, and the structure of the final answer.\n",
    "*   Researcher: Gathers and organizes relevant information needed to execute the plan.\n",
    "*   Writer: Produces or revises the draft answer based on the plan, research, and feedback.\n",
    "*   Critic: Evaluates the draft for quality, gaps, and risks, and assigns a score with concrete improvement suggestions.\n",
    "*   finalizer: Produces the final, polished answer once the quality threshold is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03357638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define structured outputs\n",
    "class Plan(BaseModel):\n",
    "    steps: List[str] = Field(..., description=\"Short ordered steps for solving the task.\")\n",
    "    key_risks: List[str] = Field(..., description=\"Major risks/unknowns that should be addressed.\")\n",
    "    desired_output_structure: List[str] = Field(..., description=\"Headings to include in final answer.\")\n",
    "\n",
    "class Critique(BaseModel):\n",
    "    issues: List[str] = Field(..., description=\"Concrete problems with the current draft.\")\n",
    "    missing_points: List[str] = Field(..., description=\"Important missing considerations.\")\n",
    "    hallucination_risk: List[str] = Field(..., description=\"Claims that might be risky without sources.\")\n",
    "    score: int = Field(..., ge=0, le=100, description=\"Overall quality score of the draft.\")\n",
    "    fix_instructions: List[str] = Field(..., description=\"Actionable steps to improve the draft.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LangGraph state\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    plan: Optional[Dict[str, Any]]\n",
    "    research_notes: List[str]\n",
    "    draft: Optional[str]\n",
    "    critique: Optional[Dict[str, Any]]\n",
    "    iteration: int\n",
    "    max_iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent nodes (Planner, Researcher, Writer, Critic, finalizer)\n",
    "\n",
    "PLANNER_SYSTEM = \"\"\"You are the Planner agent.\n",
    "Create a concise plan with steps, key risks, and final output headings.\n",
    "Return valid JSON matching the schema.\n",
    "\"\"\"\n",
    "\n",
    "RESEARCHER_SYSTEM = \"\"\"You are the Researcher agent.\n",
    "You do NOT browse the web. You reason from general knowledge.\n",
    "Produce bullet research notes covering: cost, speed, privacy, reliability, compliance, vendor lock-in, iteration speed, support.\n",
    "Keep it practical for startups.\n",
    "\"\"\"\n",
    "\n",
    "WRITER_SYSTEM = \"\"\"You are the Writer agent.\n",
    "Write a structured answer using the plan headings.\n",
    "Use the research notes.\n",
    "Be specific, actionable, and include a clear recommendation plus risks.\n",
    "\"\"\"\n",
    "\n",
    "CRITIC_SYSTEM = \"\"\"You are the Critic agent.\n",
    "Review the draft for:\n",
    "- missing points\n",
    "- weak reasoning\n",
    "- overconfidence\n",
    "- risky claims\n",
    "Return JSON matching the schema.\n",
    "\"\"\"\n",
    "\n",
    "FUNALIZER_SYSTEM = \"\"\"You are the finalizer agent.\n",
    "Given the plan + research notes + (optional) critique, produce the FINAL answer.\n",
    "If critique exists, incorporate fixes.\n",
    "Output must be polished and concise with headings and a confidence score.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67739837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: GraphState) -> GraphState:\n",
    "    structured_planner = llm.with_structured_output(Plan)\n",
    "    plan_obj = structured_planner.invoke([\n",
    "        SystemMessage(content=PLANNER_SYSTEM),\n",
    "        HumanMessage(content=state[\"question\"])\n",
    "    ])\n",
    "    state[\"plan\"] = plan_obj.model_dump()\n",
    "    return state\n",
    "\n",
    "def researcher_node(state: GraphState) -> GraphState:\n",
    "    resp = llm.invoke([\n",
    "        SystemMessage(content=RESEARCHER_SYSTEM),\n",
    "        HumanMessage(content=f\"Question:\\n{state['question']}\\n\\nPlan:\\n{state['plan']}\")\n",
    "    ]).content\n",
    "\n",
    "    # store as notes (simple split)\n",
    "    notes = [line.strip(\"- \").strip() for line in resp.split(\"\\n\") if line.strip()]\n",
    "    state[\"research_notes\"] = notes\n",
    "    return state\n",
    "\n",
    "def writer_node(state: GraphState) -> GraphState:\n",
    "    resp = llm.invoke([\n",
    "        SystemMessage(content=WRITER_SYSTEM),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Question:\n",
    "        {state['question']}\n",
    "\n",
    "        Plan:\n",
    "        {state['plan']}\n",
    "\n",
    "        Research notes:\n",
    "        {state['research_notes']}\n",
    "\n",
    "        If critique exists, you may improve the draft accordingly.\n",
    "        Critique:\n",
    "        {state.get('critique')}\n",
    "        \"\"\")\n",
    "            ]).content\n",
    "\n",
    "    state[\"draft\"] = resp\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def critic_node(state: GraphState) -> GraphState:\n",
    "    structured_critic = llm.with_structured_output(Critique)\n",
    "    critique_obj = structured_critic.invoke([\n",
    "        SystemMessage(content=CRITIC_SYSTEM),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "    Question:\n",
    "    {state['question']}\n",
    "\n",
    "    Draft:\n",
    "    {state['draft']}\n",
    "    \"\"\")\n",
    "        ])\n",
    "\n",
    "    state[\"critique\"] = critique_obj.model_dump()\n",
    "    state[\"iteration\"] += 1\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def finalizer_node(state: GraphState) -> GraphState:\n",
    "    resp = llm.invoke([\n",
    "        SystemMessage(content=FUNALIZER_SYSTEM),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Question:\n",
    "{state['question']}\n",
    "\n",
    "Plan:\n",
    "{state['plan']}\n",
    "\n",
    "Research notes:\n",
    "{state['research_notes']}\n",
    "\n",
    "Critique (if any):\n",
    "{state.get('critique')}\n",
    "\n",
    "Current draft (if any):\n",
    "{state.get('draft')}\n",
    "\"\"\")\n",
    "    ]).content\n",
    "\n",
    "    state[\"draft\"] = resp\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69313627",
   "metadata": {},
   "source": [
    "## Build LangGraph (conditional loop + stop condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32979719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "def should_revise(state: GraphState) -> Literal[\"revise\", \"finalize\"]:\n",
    "    score = state[\"critique\"][\"score\"]\n",
    "\n",
    "    if state[\"iteration\"] >= state[\"max_iterations\"]:\n",
    "        return \"finalize\"\n",
    "\n",
    "    if score < 80:\n",
    "        return \"revise\"\n",
    "\n",
    "    return \"finalize\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"critic\", critic_node)\n",
    "workflow.add_node(\"finalizer\", finalizer_node)\n",
    "\n",
    "workflow.set_entry_point(\"planner\")\n",
    "\n",
    "workflow.add_edge(\"planner\", \"researcher\")\n",
    "workflow.add_edge(\"researcher\", \"writer\")\n",
    "workflow.add_edge(\"writer\", \"critic\")\n",
    "\n",
    "# conditional edge to loop or finalize\n",
    "workflow.add_conditional_edges(\n",
    "    \"critic\",\n",
    "    should_revise,\n",
    "    {\n",
    "        \"revise\": \"writer\",\n",
    "        \"finalize\": \"finalizer\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"finalizer\", END)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd52d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize graph\n",
    "\n",
    "\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Graph visualization skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfff5d",
   "metadata": {},
   "source": [
    "## Run the Multi-Agent Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: GraphState = {\n",
    "    \"question\": question,\n",
    "    \"plan\": None,\n",
    "    \"research_notes\": [],\n",
    "    \"draft\": None,\n",
    "    \"critique\": None,\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "print(result[\"draft\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a3641",
   "metadata": {},
   "source": [
    "# compare single vs multi agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2093c5",
   "metadata": {},
   "source": [
    "def run_comparison(question: str):\n",
    "    print(\"====== Single Agent ======\")\n",
    "    print(single_agent_answer(question))\n",
    "    print(\"\\n\\n====== Multi-Agent (LangGraph) ======\")\n",
    "    initial_state: GraphState = {\n",
    "        \"question\": question,\n",
    "        \"plan\": None,\n",
    "        \"research_notes\": [],\n",
    "        \"draft\": None,\n",
    "        \"critique\": None,\n",
    "        \"iteration\": 0,\n",
    "        \"max_iterations\": 2,\n",
    "    }\n",
    "    result = app.invoke(initial_state)\n",
    "    print(result[\"draft\"])\n",
    "\n",
    "run_comparison(\"Should I build my AI product on open-source LLMs (self-hosted) or closed APIs in 2026 if I handle sensitive customer data?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2efe32",
   "metadata": {},
   "source": [
    "# Lets try few questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13311afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Should a startup use open-source LLMs or closed models in 2026? Consider cost, speed, privacy, and reliability.\",\n",
    "    \"We are in healthcare. Which approach is safer for compliance and auditability?\",\n",
    "    \"We need extremely low latency on-device. What should we choose and why?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    _ = single_agent_answer(q)\n",
    "    _ = app.invoke({\n",
    "        \"question\": q,\n",
    "        \"plan\": None,\n",
    "        \"research_notes\": [],\n",
    "        \"draft\": None,\n",
    "        \"critique\": None,\n",
    "        \"iteration\": 0,\n",
    "        \"max_iterations\": 1,\n",
    "    })  # traced\n",
    "\n",
    "print(\"Done. Open LangSmith project to compare traces and outputs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a6d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9ca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2be57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
